import pandas as pd
import numpy as np
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Flatten, Dense
from sklearn.model_selection import train_test_split

# Load dataset
df = pd.read_csv(r"C:\Users\ompaw\Downloads\imdb_top_1000.csv")

# Use 'Overview' as the review text
df = df.dropna(subset=['Overview'])

texts = df['Overview'].astype(str).values

# Create sentiment labels: 1 if IMDB_Rating >= 7.0 else 0
df['sentiment'] = (df['IMDB_Rating'] >= 7.0).astype(int)
labels = df['sentiment'].values

# Tokenize text
num_words = 10000
maxlen = 200

tokenizer = Tokenizer(num_words=num_words)
tokenizer.fit_on_texts(texts)
sequences = tokenizer.texts_to_sequences(texts)

x = pad_sequences(sequences, maxlen=maxlen)
y = labels

# Train-test split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# Build model
model = Sequential([
    Embedding(input_dim=num_words, output_dim=32, input_length=maxlen),
    Flatten(),
    Dense(64, activation='relu'),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train model
model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.2)

# Evaluate model
loss, accuracy = model.evaluate(x_test, y_test)
print(f"Test Accuracy: {accuracy:.2f}")

# Sample prediction
sample_review = x_test[0].reshape(1, -1)
predicted = model.predict(sample_review)[0][0]
print("Predicted Sentiment:", "Positive" if predicted > 0.5 else "Negative")
print("Actual Sentiment:", "Positive" if y_test[0] == 1 else "Negative")
